# ðŸ§ª Lab Directory - AI Agent Platform Testing & Experimentation

> **äº”æ­¥é—­çŽ¯** Scientific experimentation framework for production optimization without contract modifications

```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    STEP 1   â”‚â”€â”€â”€â–¶â”‚    STEP 2   â”‚â”€â”€â”€â–¶â”‚    STEP 3   â”‚â”€â”€â”€â–¶â”‚    STEP 4   â”‚â”€â”€â”€â–¶â”‚    STEP 5   â”‚
   â”‚   Baseline  â”‚    â”‚ Experiment  â”‚    â”‚  Analysis   â”‚    â”‚  Decision   â”‚    â”‚  Feedback   â”‚
   â”‚ Measurement â”‚    â”‚ Execution   â”‚    â”‚ & Results   â”‚    â”‚  & Deploy   â”‚    â”‚    Loop     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼                   â–¼                   â–¼
    ðŸ“Š Baseline           ðŸ§ª A/B Test         ðŸ“ˆ Statistical       âœ… Deploy          ðŸ”„ Optimize
    Regression            Execution          Analysis            Changes            Configuration
    Test (5Ã—5)           (Pilotâ†’Scale)      & Guardrails        (Gradual)          & Iterate
```

## ðŸš€ ä¸€é”®å‘½ä»¤æ¸…å• (One-Click Commands)

### Quick Start Commands
```bash
# ðŸ”¥ å®Œæ•´æµç¨‹è‡ªåŠ¨åŒ– (Full Pipeline)
./run-complete-pipeline.sh

# ðŸ“Š åŸºçº¿æµ‹è¯• (Baseline - STEP 1) 
node baseline_regression_test.js --mode=comprehensive

# ðŸ§ª è¯•ç‚¹å®žéªŒ (Pilot Experiment - STEP 2)
node run_ab_experiment.js --config=experiment.ab001.yaml --scale=pilot

# ðŸ“ˆ æ ‡å‡†å®žéªŒ (Standard Scale - STEP 2)
node run_ab_experiment.js --config=experiment.ab001.yaml --scale=standard

# ðŸŽ¯ A/Bå®žéªŒ (Full A/B Test - STEP 2)
node run_ab_experiment.js --config=experiment.ab001.yaml

# ðŸ§  å†³ç­–å¼•æ“Ž (Decision Engine - STEP 4)
node decision_engine.js --experiment_id=ab001

# ðŸ”¥ æµ¸æ³¡æµ‹è¯• (Soak Test)
node soak_test.js --duration=2h --watchdog=enabled

# ðŸ ä¸Šçº¿æ£€æŸ¥æ¸…å• (Go-Live Checklist)
node final_go_live_checklist.js

# ðŸ“‹ 20é¡¹è¦†ç›–éªŒæ”¶ (Coverage Acceptance)
node coverage_acceptance_test.js

# ðŸƒâ€â™‚ï¸ ä¸Šçº¿åŽè¿è¥ (Post-Launch Operations)
node post_launch_operations.js --day=0    # Launch day
node post_launch_operations.js --day=1-3  # Daily ops
node post_launch_operations.js --day=4-7  # A/B phase
```

## ðŸ“ ç›®å½•ç»“æž„

### ðŸ§  Core Experiment Framework
```
lab/
â”œâ”€â”€ run_ab_experiment.js          # A/Bå®žéªŒæ‰§è¡Œå¼•æ“Ž (stratified randomization)
â”œâ”€â”€ decision_engine.js             # ç»Ÿè®¡å†³ç­–å¼•æ“Ž (Accept/Reject/Continue)
â”œâ”€â”€ baseline_regression_test.js    # åŸºçº¿å›žå½’æµ‹è¯•å¥—ä»¶ (3-tier validation)
â”œâ”€â”€ coverage_acceptance_test.js    # 20é¡¹è¦†ç›–éªŒæ”¶æµ‹è¯•
â””â”€â”€ experiment.ab001.yaml          # é¦–ä¸ªA/Bæµ‹è¯•é…ç½® (assignment_policy)
```

### ðŸ“‹ Operational Procedures
```
â”œâ”€â”€ final_go_live_checklist.js     # 8é—¨å…¨ç»¿ä¸Šçº¿æ£€æŸ¥æ¸…å•
â”œâ”€â”€ post_launch_operations.js      # 7å¤©ä¸Šçº¿åŽè¿è¥èŠ‚å¥
â”œâ”€â”€ daily_operations.sh            # æ¯æ—¥è¿è¥SOPè„šæœ¬ 
â”œâ”€â”€ go_live_checklist.js           # ç”Ÿäº§å°±ç»ªéªŒè¯æ¸…å•
â””â”€â”€ soak_test.js                   # æµ¸æ³¡æµ‹è¯•ä¸Žçœ‹é—¨ç‹—æ¼”ç»ƒ
```

### ðŸ“š Documentation & Guides  
```
â”œâ”€â”€ runbook_step6.md              # STEP 6å®Œæ•´æ‰§è¡Œæ‰‹å†Œ (400+ lines)
â”œâ”€â”€ optimization_playbook.md      # æŒç»­ä¼˜åŒ–å°æŠ„ (ä»¥åŽç…§ç€è°ƒ)
â”œâ”€â”€ continuous_improvement_guide.md # æœªæ¥å¢žå¼ºè·¯çº¿å›¾
â”œâ”€â”€ ab_plan.md                    # A/Bæµ‹è¯•è®¡åˆ’ä¸Žå‡è®¾
â”œâ”€â”€ gates_spec.md                 # ç»Ÿè®¡é—¨æŽ§è§„èŒƒ
â”œâ”€â”€ baseline_suite.md             # åŸºçº¿æµ‹è¯•å¥—ä»¶è§„èŒƒ
â””â”€â”€ soak_plan.md                  # æµ¸æ³¡æµ‹è¯•è®¡åˆ’
```

### ðŸ—‚ï¸ Templates & Data
```
templates/
â”œâ”€â”€ decision.json                  # å†³ç­–æ–‡æ¡£æ¨¡æ¿
â”œâ”€â”€ next_run_recs.json            # ä¸‹æ¬¡è¿è¡ŒæŽ¨èæ¨¡æ¿
â”œâ”€â”€ findings.md                   # å®žéªŒå‘çŽ°æŠ¥å‘Šæ¨¡æ¿
â”œâ”€â”€ run_manifest.json             # è¿è¡Œæ¸…å•æ¨¡æ¿ (é…ç½®å†»ç»“)
â”œâ”€â”€ by_arm.csv                    # æŒ‰è‡‚èšåˆæ•°æ®æ¨¡æ¿
â”œâ”€â”€ agent_metrics_by_arm.csv      # æŒ‰è‡‚AgentæŒ‡æ ‡æ¨¡æ¿
â””â”€â”€ cashflow_check.csv            # èµ„é‡‘æµæ£€æŸ¥æ¨¡æ¿

temp/
â”œâ”€â”€ assignment_log.json           # åˆ†é…æ—¥å¿— (å®žæ—¶æ›´æ–°)
â”œâ”€â”€ experiment_results.json       # å®žéªŒç»“æžœæ•°æ®
â”œâ”€â”€ statistical_analysis.json     # ç»Ÿè®¡åˆ†æžè¾“å‡º
â””â”€â”€ operational_log.json          # è¿è¥äº‹ä»¶æ—¥å¿—
```

## ðŸŽ¯ æ ¸å¿ƒå®žéªŒç±»åž‹

### 1. Baseline Regression (åŸºçº¿å›žå½’)
**Purpose**: ç¡®ä¿ç³»ç»Ÿæœªé€€åŒ–ï¼Œå»ºç«‹ç¨³å®šåŸºçº¿  
**Scale**: 5Ã—5 (mini), 50Ã—50 (standard), 500Ã—500 (comprehensive)  
**Key Metrics**: Success rate drift â‰¤Â±1pp, P95 turnaround â‰¤+10%, èµ„é‡‘å®ˆæ’å…¨OK  

```bash
# è¿·ä½ åŸºçº¿æµ‹è¯• (2åˆ†é’Ÿ)
node baseline_regression_test.js --mode=mini

# æ ‡å‡†åŸºçº¿æµ‹è¯• (10åˆ†é’Ÿ)  
node baseline_regression_test.js --mode=standard

# å…¨é¢åŸºçº¿æµ‹è¯• (30åˆ†é’Ÿ)
node baseline_regression_test.js --mode=comprehensive
```

### 2. A/B Experiments (A/Bå®žéªŒ)
**Purpose**: ç§‘å­¦éªŒè¯é…ç½®å˜æ›´å¯¹å…³é”®æŒ‡æ ‡çš„å½±å“  
**Phases**: Pilot (5Ã—5) â†’ Small Scale (500Ã—500) â†’ Full Scale (2000Ã—2000)  
**Statistical Tests**: Two-proportion Z-test, Mann-Whitney U, Effect size analysis  

```bash
# å½“å‰å®žéªŒ: assignment_policy (uniform vs weighted_by_score)
node run_ab_experiment.js --config=experiment.ab001.yaml

# æ£€æŸ¥å®žéªŒçŠ¶æ€
node experiment_status.js --experiment_id=ab001

# æå‰åœæ­¢å®žéªŒ (å¦‚æžœè¾¾åˆ°ç»Ÿè®¡æ˜¾è‘—æ€§)
node experiment_stop.js --experiment_id=ab001 --reason=early_success
```

### 3. Soak Testing (æµ¸æ³¡æµ‹è¯•) 
**Purpose**: é•¿æ—¶é—´ç¨³å®šæ€§éªŒè¯ï¼Œçœ‹é—¨ç‹—æœºåˆ¶æ¼”ç»ƒ  
**Duration**: 1-8å°æ—¶å¯é…ç½®  
**Monitors**: Watchdog triggers, circuit breaker events, memory leaks, performance degradation  

```bash
# 2å°æ—¶æµ¸æ³¡æµ‹è¯•
node soak_test.js --duration=2h --watchdog=enabled

# è½»é‡çº§çœ‹é—¨ç‹—æ¼”ç»ƒ
node watchdog_drill.js --type=load_shedding --severity=mild

# åŠç†”æ–­æ¼”ç»ƒ
node watchdog_drill.js --type=circuit_breaker --severity=semi
```

## ðŸ“Š Metric Categories & Thresholds

### ðŸŽ¯ Primary Success Metrics
- **Success Rate**: Target >85%, Minimum improvement +2pp for significance
- **Cost Per Success**: Target <0.002 native tokens, Non-regression threshold +5%
- **P95 Turnaround Time**: Target <10s, Acceptable degradation +10%

### ðŸ›¡ï¸ Guardrail Metrics  
- **Arbitration Rate**: Threshold <8%, Quality assurance floor
- **Deadline Violation Rate**: Threshold <15%, User experience protection
- **System Error Rate**: Threshold <1%, Platform stability
- **Agent Churn Rate**: Threshold <5% monthly, Ecosystem health

### ðŸ“ˆ Business Impact Metrics
- **Revenue per Agent**: Economic efficiency indicator
- **User Satisfaction Score**: NPS-style feedback aggregation  
- **Platform Utilization**: Agent capacity optimization
- **Discovery Rate**: New high-performing agents per week

## ðŸ”„ Experiment Lifecycle

### Phase 1: Planning & Design (STEP 1-2)
1. **Hypothesis Formation** - Clear, measurable, falsifiable
2. **Sample Size Calculation** - Statistical power analysis (Î² â‰¥ 80%)
3. **Randomization Strategy** - Stratified by difficulty, category, agent pool
4. **Success Criteria** - Primary/secondary metrics, guardrails, business impact

### Phase 2: Execution (STEP 2-3)
1. **Pilot Run** - Small scale validation (5Ã—5)
2. **Standard Scale** - Representative sample (500Ã—500)  
3. **Full Scale** - Production-scale test (2000Ã—2000)
4. **Real-time Monitoring** - Automated alerts, guardrail checks, data quality gates

### Phase 3: Analysis & Decision (STEP 4)
1. **Statistical Analysis** - Significance tests, effect size, confidence intervals
2. **Guardrail Validation** - All safety thresholds checked
3. **Business Impact Assessment** - ROI calculation, user experience impact
4. **Decision Framework** - Accept/Reject/Continue based on gates_spec.md

### Phase 4: Deployment & Feedback (STEP 5)
1. **Gradual Rollout** - 25% â†’ 50% â†’ 100% with monitoring
2. **Post-deployment Monitoring** - 30-day observation period  
3. **Configuration Update** - Update experiment.config.yaml with winning arm
4. **Feedback Loop** - Insights feed into next experiment cycle

## ðŸŽ›ï¸ Configuration Management

### Environment Configuration
```yaml
# experiment.ab001.yaml - Core A/B test configuration
experiment_id: "ab001_assignment_policy"
hypothesis: "weighted_by_score improves success rate â‰¥2pp vs uniform"
arms:
  A: { assignment_policy: "uniform" }          # Control
  B: { assignment_policy: "weighted_by_score" } # Treatment
sample_size: 2000  # Per arm
success_criteria:
  primary: "success_rate"
  minimum_lift: 0.02  # 2 percentage points
  significance_level: 0.05
```

### Schema Version Control
- **event_schema_v1.0.json** - Frozen schema for data consistency
- **run_manifest.json** - SHA256 hashes for configuration freeze
- **config_version_history.json** - Change tracking and rollback capability

## ðŸš¨ Monitoring & Alerting

### Real-time Alerts
```bash
# Alert thresholds (customizable)
SUCCESS_RATE_DROP_THRESHOLD=0.02      # 2pp drop triggers alert
COST_INCREASE_THRESHOLD=0.15          # 15% cost increase  
P95_LATENCY_SPIKE_THRESHOLD=1.2       # 20% latency spike
ARBITRATION_QUEUE_THRESHOLD=50        # Queue length alert
```

### Dashboard Metrics
- **Live Experiment Status** - Current experiments, sample sizes, significance
- **Health Indicators** - System stability, agent performance, user satisfaction  
- **Business KPIs** - Revenue trends, cost efficiency, growth metrics
- **Quality Scorecard** - Arbitration results, user feedback, agent calibration

## ðŸ› ï¸ Troubleshooting Guide

### Common Issues

**âŒ Experiment Not Converging**
```bash
# Check sample balance
node experiment_diagnostics.js --check=randomization_balance

# Increase sample size  
node experiment_scale.js --experiment_id=ab001 --scale_factor=1.5

# Reduce noise with stratification
node experiment_update.js --experiment_id=ab001 --add_stratification=agent_tier
```

**âŒ Statistical Power Too Low**  
```bash
# Calculate required sample size
node power_analysis.js --effect_size=0.02 --power=0.8 --alpha=0.05

# Extend experiment duration
node experiment_extend.js --experiment_id=ab001 --additional_days=3
```

**âŒ Guardrail Violations**
```bash  
# Immediate experiment pause
node experiment_pause.js --experiment_id=ab001 --reason=guardrail_violation

# Root cause analysis
node guardrail_analysis.js --experiment_id=ab001 --metric=arbitration_rate

# Rollback plan execution
node rollback.js --to_baseline --verify_safety=true
```

## ðŸ“ˆ Success Stories & Benchmarks

### Historical Improvements
- **Assignment Policy Optimization**: +3.49% success rate improvement
- **Difficulty Curve Calibration**: -12% cost per success reduction  
- **Retry Strategy Enhancement**: +7% overall completion rate
- **Payment Mode Balance**: +5% user satisfaction improvement

### Performance Benchmarks
- **Experiment Execution Time**: Pilot (2min), Standard (10min), Full (30min)
- **Statistical Confidence**: 95% significance level maintained
- **Rollback Time**: <30 seconds automated, <5 minutes manual
- **Data Quality**: 99.9% unique key hit rate, 100% fund conservation

## ðŸ”® Future Roadmap

### Planned Enhancements
1. **Multi-Armed Bandit Algorithms** - Dynamic resource allocation
2. **Factorial Experiment Design** - Multi-variable optimization  
3. **Drift Detection System** - Automatic performance degradation alerts
4. **Cross-Chain Deployment** - L2 testnet and mainnet support
5. **Predictive Maintenance** - AI-powered proactive optimization

### Integration Capabilities  
- **External Analytics** - Google Analytics, Mixpanel, Amplitude
- **Notification Systems** - Slack, Discord, Email, SMS alerts
- **CI/CD Integration** - GitHub Actions, Jenkins pipeline support  
- **Data Warehouse** - BigQuery, Snowflake, Redshift connectors

---

## ðŸ“ž Support & Contact

### Documentation
- **Full Technical Specs**: See individual `.md` files in `/lab` directory
- **API Reference**: Generated from inline code documentation
- **Video Tutorials**: Available in `/docs/tutorials/` (coming soon)

### Getting Help
- **Issue Tracking**: File issues in GitHub repository
- **Community Forum**: Join Discord for community support
- **Enterprise Support**: Contact team for dedicated assistance

### Contributing
- **Pull Requests**: Welcome! See `CONTRIBUTING.md` for guidelines
- **Bug Reports**: Use issue templates for consistent reporting
- **Feature Requests**: Propose enhancements via GitHub Discussions

---

**ðŸŽ‰ Ready to optimize your AI Agent platform scientifically? Start with baseline measurement!**

```bash
# Your journey begins here
node baseline_regression_test.js --mode=standard
```